<details><summary>Текст задания</summary>
# Лабораторная работа №1: Проектирование сервиса сокращения URL<br>
<br>
Постановка задачи: Вы должны спроектировать сервис сокращения URL, аналогичный TinyURL. Сервис должен принимать длинный URL и возвращать уникальный короткий URL. При переходе по короткому URL пользователь должен быть перенаправлен на исходный длинный URL.<br>
<br>
Функциональные требования:<br>
<br>
1. Пользователь может ввести длинный URL и получить короткий. — сколько символов?<br>
    <br>
2. При переходе по короткому URL происходит HTTP-редирект на оригинальный URL.<br>
    <br>
3. Пользователи могут задавать кастомные короткие URL (псевдонимы). — Ограничения?<br>
    <br>
4. Короткие URL должны иметь ограниченный срок действия (например, 1 год). — могут спросить про другое время<br>
    <br>
<br>
Нефункциональные требования:<br>
<br>
5. Высокая доступность: Сервис должен быть доступен 99.9% времени.<br>
    <br>
6. Низкая задержка: Редирект должен происходить как можно быстрее (<100 мс).<br>
    <br>
7. Масштабируемость: Система должна быть рассчитана на 10 миллионов новых URL в месяц. Соотношение чтений (редиректов) к записям (создание URL) — 100:1.<br>
<br>
<br>
Задания:<br>
<br>
8. Оценочные расчеты: Рассчитайте ожидаемое количество запросов в секунду (QPS) на чтение и запись, а также требуемый объем хранилища на 5 лет.<br>
    <br>
9. Проектирование API: Определите эндпоинты REST API для создания и получения URL.<br>
    <br>
10. Модель данных: Спроектируйте схему базы данных. Обоснуйте выбор между SQL и NoSQL.<br>
    <br>
11. Технические решения:<br>
    <br>
<br>
- Предложите и сравните 2-3 алгоритма для генерации уникальной короткой части URL (например, хэширование + Base62, инкрементальный счетчик + Base62).<br>
    <br>
- Опишите, как будет реализована поддержка кастомных псевдонимов и как обрабатывать конфликты.<br>
    <br>
- Предложите стратегию кэширования для ускорения редиректов.<br>
    <br>
<br>
1. UML-диаграмма: Нарисуйте компонентную диаграмму высокого уровня, показывающую основные сервисы (например, веб-сервер, сервис приложений, базу данных, кэш) и связи между ними.<br>
    <br>
2. Анализ узких мест: Определите потенциальные узкие места в вашем дизайне (например, генерация уникальных ключей при высокой нагрузке на запись, нагрузка на базу данных) и предложите способы их устранения.<br>
    <br>
</details>
---
1. Оценочные расчёты — исходя из нефункционального требования масштабируемости — "10 миллионов новых URL в месяц" и "Соотношение чтений (редиректов) к записям (создание URL) — 100:1" — считаем:
	
	10 000 000 записей ⋅ 100 чтений = 1 000 000 000 запросов за месяц
	-
	1 000 000 000 / (30 ⋅ 24 ⋅ 60 ⋅ 60) = **385** запросов в секунду
	-
	Записи хранятся ограниченное количество времени — по функциональному требованию 4 — 1 год
	-
	10 000 000 записей в месяц ⋅ 1 год ⋅ 12 месяцев = 120 000 000 записей в год
	120 000 000 записей в год ⋅ 5 лет = **600 000 000** записей на 5 лет
	-
	Допустим, что: 
		URL создаётся из алфавита доступных для URL символов в Base62 (26 английских букв ⋅ 2 + 10 арабских цифр) размером 62 символов.
	-
	Тогда, для обеспечения хорошей защиты от коллизий, при этом сохранив краткость можно использовать 5 символов. Это даст 916 132 832 возможных комбинаций, чего должно хватить на 600 000 000 записей за 5 лет
	-
	Если хранить только ключ без адреса нашего сервиса, то это будет 5 байт на ключ. Соответственно, 
	5 байт ⋅ 600 000 000 записей = 3 000 000 000 байт = 2.79 Гб за 5 лет
	-
	В среднем URL с протоколом занимает [от 25 до 50 знаков](https://www.researchgate.net/publication/360254493_An_Adversarial_Attack_Analysis_on_Malicious_Advertisement_URL_Detection_Framework) — возьмём верхнюю границу в 50 — 50 байт
	50 байт ⋅ 600 000 000 записей = 30 000 000 000 байт = 27.94 Гб за 5 лет
	-
	Итого около 30.73 Гб
	-
	Время удаления учитывать не нужно, так как в таких СУБД как Redis можно задать время жизни той или иной записи — после чего она не будет числится в базе данных. 
2. Проектирование API 
	Эндпоинты следующие:
	- `/[0-9a-zA-Z]` — поиск ссылки по ключу и перенаправление по ней
	- `/new` — создание ссылки
	- `/upd/[0-9a-zA-Z]` — Изменение ссылки
	- `/del/[0-9a-zA-Z]` — удаление ссылки 
	- `/log` и `/reg` — логин и регистрация соответственно. В основном потребуется для админки/платных фич
	
3. Модель данных
	Для скорости обработки пользовательских данных — простые ассоциации ключей и полных ссылок — отлично подойдёт InMemory NoSQL база данных вроде Redis/Valkey/Memcached. Они не требуют сложных запросов, их просто развернуть или арендовать у провайдеров, а обращение за полной ссылкой по ключу в ОЗУ работает быстрее, чем другие решения, которые считывают данные с диска.
	-
	Модель данных представляет собой простую пару ключ-значение.
	-
	Также для администрирования и разделения доступа к фичам подразумевается РСУБД (PostgreSQL, MySQL) — хранение данных о пользователе, их роли и их ссылках
	
4. Технические решения
	Для получения короткой ссылки можно использовать кодирование Base62, как описано выше. Для получения исходной строки, передаваемой в кодировщик можно использовать следующие стратегии:
		- Base62 на основе случайного хэша (пример MD5)
		- Base62 на основе инкрементируемого счётчика 
		- Base62 на основе хэша с элементом HashRing — общее хранилище делится на N шардов и по первому символу в ключе определяется шард, в котором хранится ключ-значение
	-
	Наивный подход: В обоих случаях, если пользователь предлагает кастомный псевдоним, то его нужно проверить в базе данных на коллизии запросом, и если нет коллизии, то ссылка создаётся. В противном случае возвращается ошибка.
	-
	Стратегия кэширования 
	В первых двух случаях InMemory базы данных используются для быстрого получения полной ссылки по ключу —  поэтому несколько реплик такой БД вполне заменят отдельную инфраструктуру для кэширования. Пользовательские данные хранятся на двух реляционных БД с репликацией active-active
	-
	В случае с HashRing подойдёт простая lazy-loading стратегия, когда ссылка кэшируется при её запросе. Также, пользуясь функциями многих InMemory СУБД можно расставлять приоритеты кэшируемым ссылкам для того, чтобы в кэше были только самые популярные ссылки. 

## Короче

- Базы данных — дублированы для Redundancy по схеме Active-Active (обе базы будут работать быстро ввиду несложности модели обрабатываемых данных)
	- 2 редиса — хранят ссылки в кэше
	- 2 постгреса — хранят пользовательские данные
- Сервера
	- 2–4 сервера для создания ссылок
	- 2–6 серверов для получения ссылок
- Load balancer

```yaml
---
config:
  theme: redux
  layout: fixed
---
flowchart TD
    Load_balancer["Load_balancer"] ---> Management_server["Create_server"] & Redirect_server["Redirect_server"]
    Management_server ---> n1["User_DB"] & n2["Link_DB"]
    Redirect_server ---> n1 & n2
    n1@{ shape: db} 
    n2@{ shape: db}

```
## Анализ узких мест

- Не удаётся предсказать, занят ли ключ, предложенный пользователем вплоть до отправки запроса — но так как запрос к кэшу быстрый, то сервер может очень быстро вернуть ошибку и (если предусмотреть этот алгоритм) предложит схожие псевдонимы.
- Сильно нагружен узел записи и управления ссылками — он отвечает за слишком большое количество задач по управлению ссылками и профилями пользователей. Тем не менее, сервис в первую очередь рассчитан на редирект ссылок, поэтому этот аспект инфраструктуры можно масштабировать позже за счёт создания новых инстансов сервиса или разделения их на микросервисы авторизации и создания/удаления ссылок
- В случае необходимости удаления ссылки модератором при асинхронной синхронизации на InMemory БД кэш инвалидируется не сразу, поэтому удалённая ссылка может работать ещё некоторое время